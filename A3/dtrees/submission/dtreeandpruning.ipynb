{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import pandas as pd\n",
    "from xclib.data import data_utils\n",
    "import matplotlib.pylab as plt\n",
    "from random import seed\n",
    "from random import randrange\n",
    "import math\n",
    "import time\n",
    "import numexpr as ne\n",
    "from multiprocessing import Pool\n",
    "from joblib import Parallel, delayed\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "data_folder_path = './data/'\n",
    "train_x_path = data_folder_path + 'train_x.txt'\n",
    "train_y_path = data_folder_path + 'train_y.txt'\n",
    "train_size = (64713, 482)\n",
    "test_x_path = data_folder_path + 'test_x.txt'\n",
    "test_y_path = data_folder_path + 'test_y.txt'\n",
    "test_size = (21571, 482)\n",
    "val_x_path = data_folder_path + 'valid_x.txt'\n",
    "val_y_path = data_folder_path + 'valid_y.txt'\n",
    "val_size = (21572, 482)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_y(path, size):\n",
    "    y = np.ones(size)\n",
    "    f = open(path)\n",
    "    cnt = 0\n",
    "    for x in f:\n",
    "        y[cnt] = int(x)\n",
    "        cnt += 1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, predicted_class):\n",
    "        self.predicted_class = predicted_class\n",
    "        self.feature_index = 0\n",
    "        self.threshold = 0\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.index = 1\n",
    "        self.depth = 0\n",
    "\n",
    "\n",
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.n_classes_ = len(set(y))\n",
    "        self.n_features_ = X.shape[1]\n",
    "        self.tree_ = self._grow_tree(X, y, 1)\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        return [self._predict(inputs) for inputs in X]\n",
    "\n",
    "    def _entropy(self, X, y):\n",
    "        m = y.size\n",
    "        n = X.shape[0]\n",
    "        a2 = np.count_nonzero(y==1)\n",
    "        a1 = m - a2\n",
    "        \n",
    "        # print('ggg', a1, a2)\n",
    "        if(a1==0):\n",
    "            return 0\n",
    "        elif(a2==0):\n",
    "            return 1\n",
    "        return (-1 * (a1/y.shape[0]) * math.log2((a1/y.shape[0])) + (-1 * (a2/y.shape[0]) * math.log2((a2/y.shape[0]))))\n",
    "\n",
    "            # return 0.5\n",
    "    def _tovectoriz(self, X, y, idx, entropy_class):\n",
    "        # print(idx)\n",
    "        median = np.median(X[:, idx])\n",
    "        \n",
    "        data_left = np.array([np.array([i, clas]) for i,clas in zip(X[:, idx],y) if i<=median])\n",
    "        if(data_left.size==0):\n",
    "            entropy_left = 0\n",
    "            size0 = 0\n",
    "        else:\n",
    "            entropy_left = self._entropy(data_left[:,0], data_left[:,1])\n",
    "            size0 = data_left[:,1].shape[0]\n",
    "\n",
    "        \n",
    "        data_right = np.array([np.array([i, clas]) for i,clas in zip(X[:, idx],y) if i>median])\n",
    "        if(data_right.size==0):\n",
    "            entropy_right = 0\n",
    "            size1 = 0\n",
    "        else:\n",
    "            entropy_right = self._entropy(data_right[:,0], data_right[:,1])\n",
    "            size1 = data_right[:,1].shape[0]\n",
    "        \n",
    "        temp = size0/(size0+size1)\n",
    "        varr = (temp * entropy_left + (1-temp) * entropy_right)\n",
    "        return varr\n",
    "\n",
    "    # Return best attribute for splitting data with its corresponding threshold to split.\n",
    "    def _best_split(self, X, y):\n",
    "        m = y.size\n",
    "        n = X.shape[1]\n",
    "        if m<=1:\n",
    "            return None, None\n",
    "        \n",
    "        best_idx, best_thr = None, None\n",
    "        entropy_class = self._entropy(X, y)\n",
    "        \n",
    "        entropy_attr = [(entropy_class - self._tovectoriz(X, y, i, entropy_class)) for i in range(n)]\n",
    "        \n",
    "        # entropy_attr = [0] * n\n",
    "        # for i in range(n):\n",
    "        #     remp = self._tovectoriz(X, y, i, entropy_class)\n",
    "        #     # if(remp>entropy_class):\n",
    "        #     #     print(remp, entropy_class)\n",
    "        #     #     return None, None\n",
    "        #     entropy_attr[i] = entropy_class - self._tovectoriz(X, y, i, entropy_class)\n",
    "\n",
    "        # entropy_attr = [0] * (n)\n",
    "        # entropy_attr = Parallel(n_jobs=-1, verbose=0, backend=\"threading\")(map(delayed(self._tovectoriz), X, y, i, entropy_class))\n",
    "\n",
    "        # print(entropy_attr)\n",
    "        # if(np.count_nonzero(np.array(entropy_attr)==0)==len(entropy_attr)):\n",
    "        #     return None, None\n",
    "        best_idx = np.argmax(entropy_attr)\n",
    "        best_thr = np.median(X[:,best_idx])\n",
    "        if(entropy_attr[best_idx]>=entropy_class):\n",
    "            return None, None\n",
    "        \n",
    "        return best_idx, best_thr\n",
    "\n",
    "#     def _best_split_old(self, X, y):\n",
    "#         m = y.size\n",
    "#         if m <= 1:\n",
    "#             return None, None\n",
    "#         num_parent = [np.sum(y == c) for c in range(self.n_classes_)]\n",
    "#         best_gini = 1.0 - sum((n / m) ** 2 for n in num_parent)\n",
    "#         best_idx, best_thr = None, None\n",
    "#         for idx in range(self.n_features_):\n",
    "#             thresholds, classes = zip(*sorted(zip(X[:, idx], y)))\n",
    "#             num_left = [0] * self.n_classes_\n",
    "#             num_right = num_parent.copy()\n",
    "#             for i in range(1, m):\n",
    "#                 c = int(classes[i - 1])\n",
    "#                 num_left[c] += 1\n",
    "#                 num_right[c] -= 1\n",
    "#                 gini_left = 1.0 - sum(\n",
    "#                     (num_left[x] / i) ** 2 for x in range(self.n_classes_)\n",
    "#                 )\n",
    "#                 gini_right = 1.0 - sum(\n",
    "#                     (num_right[x] / (m - i)) ** 2 for x in range(self.n_classes_)\n",
    "#                 )\n",
    "#                 gini = (i * gini_left + (m - i) * gini_right) / m\n",
    "#                 if thresholds[i] == thresholds[i - 1]:\n",
    "#                     continue\n",
    "#                 if gini < best_gini:\n",
    "#                     best_gini = gini\n",
    "#                     best_idx = idx\n",
    "#                     best_thr = (thresholds[i] + thresholds[i - 1]) / 2\n",
    "#                 # print(best_idx, best_thr)\n",
    "#         # print(best_idx, best_thr)\n",
    "#         return best_idx, best_thr\n",
    "\n",
    "    # Return best attribute for splitting data with its corresponding threshold to split.\n",
    "#     def _best_split(self, X, y):\n",
    "#         m = y.size\n",
    "#         if m <= 10:\n",
    "#             return None, None\n",
    "#         num_parent = [np.sum(y == c) for c in range(self.n_classes_)]\n",
    "#         try:\n",
    "#             best_entropy = -1.0 * sum((n / m) * (math.log2((n / m))) for n in num_parent)\n",
    "#         except:\n",
    "#             best_entropy = 0\n",
    "#         best_idx, best_thr = None, None\n",
    "#         for idx in range(self.n_features_):\n",
    "#             thresholds, classes = zip(*sorted(zip(X[:, idx], y)))\n",
    "#             num_left = [0] * self.n_classes_\n",
    "#             num_right = num_parent.copy()\n",
    "#             for i in range(1, m):\n",
    "#                 c = int(classes[i - 1])\n",
    "#                 num_left[c] += 1\n",
    "#                 num_right[c] -= 1\n",
    "#                 try:\n",
    "#                     entropy_left = -1.0 * sum((num_left[x] / i) * (math.log2((num_left[x] / i))) for x in range(self.n_classes_))\n",
    "#                 except:\n",
    "#                     entropy_left = 0\n",
    "#                 try:\n",
    "#                     entropy_right = -1.0 * sum((num_right[x] / (m - i)) * (math.log2((num_right[x] / (m - i)))) for x in range(self.n_classes_))\n",
    "#                 except:\n",
    "#                     entropy_right = 0\n",
    "#                 entropy = (i * entropy_left + (m - i) * entropy_right) / m\n",
    "#                 if thresholds[i] == thresholds[i - 1]:\n",
    "#                     continue\n",
    "#                 if entropy < best_entropy:\n",
    "#                     best_entropy = entropy\n",
    "#                     best_idx = idx\n",
    "#                     best_thr = (thresholds[i] + thresholds[i - 1]) / 2\n",
    "#                 # print(best_idx, best_thr)\n",
    "#         # print(best_idx, best_thr)\n",
    "#         return best_idx, best_thr\n",
    "\n",
    "    def _grow_tree(self, X, y, index, depth=0):\n",
    "        num_samples_per_class = [np.sum(y == i) for i in range(2)]\n",
    "        predicted_class = np.argmax(num_samples_per_class)\n",
    "        node = Node(predicted_class=predicted_class)\n",
    "        node.index = index\n",
    "#         print(depth)\n",
    "        idx = -1\n",
    "        if depth < self.max_depth:\n",
    "            idx, thr = self._best_split(X, y)\n",
    "            if idx is not None:\n",
    "                node.feature_index = idx\n",
    "                node.threshold = thr\n",
    "                node.left = self._grow_tree(X[X[:,idx]<=thr],  y[X[:, idx]<=thr], node.index*2, depth + 1)\n",
    "                node.left.depth = depth + 1\n",
    "                node.right = self._grow_tree(X[X[:, idx]>thr], y[X[:, idx]>thr], node.index*2+1, depth + 1)\n",
    "                node.right.depth = depth + 1\n",
    "\n",
    "        return node\n",
    "\n",
    "    def _predict(self, inputs):\n",
    "        node = self.tree_\n",
    "        while node.left:\n",
    "            if inputs[node.feature_index] <= node.threshold:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "        return node.predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(clf, a, b):\n",
    "    i = 0\n",
    "    cnt = 0\n",
    "    for x in clf.predict(a):\n",
    "        if(x==b[i]):\n",
    "            cnt += 1\n",
    "        i+=1\n",
    "    return (cnt/i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karan/.local/lib/python3.6/site-packages/xclib-0.96-py3.6-linux-x86_64.egg/xclib/data/data_utils.py:173: UserWarning: Header mis-match from inferred shape!\n",
      "  warnings.warn(\"Header mis-match from inferred shape!\")\n"
     ]
    }
   ],
   "source": [
    "# FUNCTION CALLING STARTS\n",
    "# DATA LOADING...\n",
    "train_x = data_utils.read_sparse_file(train_x_path)\n",
    "train_y = load_y(train_y_path, train_x.shape[0])\n",
    "\n",
    "test_x = data_utils.read_sparse_file(test_x_path)\n",
    "test_y = load_y(test_y_path, test_x.shape[0])\n",
    "\n",
    "val_x = data_utils.read_sparse_file(val_x_path)\n",
    "val_y = load_y(val_y_path, val_x.shape[0])\n",
    "\n",
    "i = 0\n",
    "train_data = np.zeros(shape=train_size)\n",
    "for x in train_x.toarray():\n",
    "    train_data[i] = [int(i) for i in x]\n",
    "    i += 1\n",
    "# train_data = train_data[:100, :]\n",
    "# train_y = train_y[:100]\n",
    "\n",
    "i = 0\n",
    "test_data = np.zeros(shape=test_size)\n",
    "for x in test_x.toarray():\n",
    "    test_data[i] = [int(i) for i in x]\n",
    "    i += 1\n",
    "# test_data = test_data[:100, :]\n",
    "# test_y = test_y[:100]\n",
    "\n",
    "i = 0\n",
    "val_data = np.zeros(shape=val_size)\n",
    "for x in val_x.toarray():\n",
    "    val_data[i] = [int(i) for i in x]\n",
    "    i += 1\n",
    "# val_data = val_data[:100, :]\n",
    "# val_y = val_y[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = train_data, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time:  57.10534771680832\n"
     ]
    }
   ],
   "source": [
    "# DEFINE CLASSIFIER\n",
    "clf = DecisionTreeClassifier(max_depth=40)\n",
    "start = time.time()\n",
    "clf.fit(X, y)\n",
    "print('Training Time: ', (time.time()-start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = deque()\n",
    "q.append(clf.tree_)\n",
    "\n",
    "ll = []\n",
    "cnt = 0\n",
    "while(q):\n",
    "    temp = q.popleft()\n",
    "    if(temp is None):\n",
    "        continue\n",
    "    if(temp and temp.left is not None):\n",
    "        q.append(temp.left)\n",
    "    if(temp and temp.right is not None):\n",
    "        q.append(temp.right)\n",
    "    ll.append(temp.index)\n",
    "\n",
    "    # print('index and depth: ', temp.index, temp.depth)\n",
    "    cnt += 1\n",
    "\n",
    "# print(ll)\n",
    "index_max = ll[len(ll)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 0.8732557600482129\n",
      "Train accuracy 0.7785916276482314\n",
      "Val accuracy 0.7781846838494344\n"
     ]
    }
   ],
   "source": [
    "print('Train accuracy', get_accuracy(clf, train_data, train_y))\n",
    "\n",
    "print('Train accuracy', get_accuracy(clf, test_data, test_y))\n",
    "\n",
    "print('Val accuracy', get_accuracy(clf, val_data, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17284"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PRUNING STARTS\n",
    "lll = ll[:1800]\n",
    "lll[len(lll)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pruning starts...\n",
      "0.7849527164843315 0.7849990728722418\n",
      "0.7849990728722418 0.7850454292601521\n",
      "0.7850454292601521 0.7851844984238828\n",
      "0.7851844984238828 0.7852308548117931\n",
      "0.7852308548117931 0.7854626367513443\n",
      "0.7854626367513443 0.7859725570183571\n",
      "0.7859725570183571 0.786853328388652\n",
      "0.786853328388652 0.7869460411644724\n",
      "0.7869460411644724 0.7869923975523827\n",
      "0.7869923975523827 0.787038753940293\n",
      "0.787038753940293 0.7883830891896904\n",
      "0.7883830891896904 0.7886612275171518\n",
      "0.7886612275171518 0.7887075839050621\n",
      "0.7887075839050621 0.7887539402929724\n",
      "0.7887539402929724 0.7888002966808826\n",
      "0.7888002966808826 0.7888466530687929\n",
      "0.7888466530687929 0.7888930094567032\n",
      "0.7888930094567032 0.7894956424995364\n",
      "0.7894956424995364 0.7896347116632672\n",
      "0.7896347116632672 0.7896810680511774\n",
      "0.7896810680511774 0.789773780826998\n",
      "0.789773780826998 0.7898201372149082\n",
      "0.7898201372149082 0.7898664936028185\n",
      "0.7898664936028185 0.7899592063786389\n",
      "0.7899592063786389 0.79014463193028\n",
      "0.79014463193028 0.7901909883181902\n",
      "0.7901909883181902 0.7902373447061005\n",
      "0.7902373447061005 0.7902837010940108\n",
      "0.7902837010940108 0.7904227702577415\n",
      "0.7904227702577415 0.7904691266456517\n",
      "0.7904691266456517 0.790515483033562\n",
      "0.790515483033562 0.7905618394214723\n",
      "0.7905618394214723 0.7906081958093826\n",
      "0.7906081958093826 0.7906545521972927\n",
      "0.7906545521972927 0.7910254033005748\n",
      "0.7910254033005748 0.7910717596884851\n",
      "0.7910717596884851 0.7913498980159466\n",
      "0.7913498980159466 0.7914426107917671\n",
      "0.7914426107917671 0.7914889671796773\n",
      "0.7914889671796773 0.7916743927313183\n",
      "0.7916743927313183 0.7917671055071389\n",
      "0.7917671055071389 0.7918134618950491\n",
      "0.7918134618950491 0.7918598182829594\n",
      "0.7918598182829594 0.7919525310587799\n",
      "0.7919525310587799 0.7920452438346004\n",
      "0.7920452438346004 0.7920916002225107\n",
      "0.7920916002225107 0.7921843129983311\n"
     ]
    }
   ],
   "source": [
    "print('pruning starts...')\n",
    "best_score = get_accuracy(clf, val_data, val_y)\n",
    "lx = [cnt]\n",
    "l_val = [best_score]\n",
    "l_train = [get_accuracy(clf, train_data, train_y)]\n",
    "l_test = [get_accuracy(clf, test_data, test_y)]\n",
    "for x in lll:\n",
    "    q = deque()\n",
    "    q.append(clf.tree_)\n",
    "    left = None\n",
    "    right = None\n",
    "    pruned_depth = None\n",
    "    while(q):\n",
    "        temp = q.popleft()\n",
    "        if(temp is None):\n",
    "            continue\n",
    "        if(temp.left==None and temp.right==None):\n",
    "            continue\n",
    "        if(temp and temp.left is not None):\n",
    "            q.append(temp.left)\n",
    "        if(temp and temp.right is not None):\n",
    "            q.append(temp.right)\n",
    "\n",
    "        # ll.append(temp.index)\n",
    "        if(temp.index==x):\n",
    "            # print('pruned!!')\n",
    "            left = temp.left\n",
    "            right = temp.right\n",
    "            pruned_depth = temp.depth\n",
    "#             print(temp.depth)\n",
    "            temp.left = None\n",
    "            temp.right = None\n",
    "            break\n",
    "\n",
    "    now_score = get_accuracy(clf, val_data, val_y)\n",
    "    # print('Now score: ', now_score)\n",
    "    if(now_score>best_score):\n",
    "        print(best_score, now_score)\n",
    "        best_score = now_score\n",
    "        cnt += 2**(pruned_depth-4)\n",
    "        lx.append(lx[0]-cnt)\n",
    "        l_val.append(best_score)\n",
    "        l_train.append(get_accuracy(clf, train_data, train_y))\n",
    "        l_test.append(get_accuracy(clf, test_data, test_y))\n",
    "    else:\n",
    "        temp.left = left\n",
    "        temp.right = right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# curry = lx[0]\n",
    "for i in range(1, len(lx)):\n",
    "#     curry \n",
    "    lx[i] = lx[i-1] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val accuracy 0.7921843129983311\n",
      "[9518.75, 9517.75, 9516.75, 9515.75, 9514.75, 9513.75, 9512.75, 9511.75, 9510.75, 9509.75, 9508.75, 9507.75, 9506.75, 9505.75, 9504.75, 9503.75, 9502.75, 9501.75, 9500.75, 9499.75, 9498.75, 9497.75, 9496.75, 9495.75, 9494.75, 9493.75, 9492.75, 9491.75, 9490.75, 9489.75, 9488.75, 9487.75, 9486.75, 9485.75, 9484.75, 9483.75, 9482.75, 9481.75, 9480.75, 9479.75, 9478.75, 9477.75, 9476.75, 9475.75, 9474.75, 9473.75, 9472.75, 9471.75]\n",
      "[0.7849527164843315, 0.7849990728722418, 0.7850454292601521, 0.7851844984238828, 0.7852308548117931, 0.7854626367513443, 0.7859725570183571, 0.786853328388652, 0.7869460411644724, 0.7869923975523827, 0.787038753940293, 0.7883830891896904, 0.7886612275171518, 0.7887075839050621, 0.7887539402929724, 0.7888002966808826, 0.7888466530687929, 0.7888930094567032, 0.7894956424995364, 0.7896347116632672, 0.7896810680511774, 0.789773780826998, 0.7898201372149082, 0.7898664936028185, 0.7899592063786389, 0.79014463193028, 0.7901909883181902, 0.7902373447061005, 0.7902837010940108, 0.7904227702577415, 0.7984691266456517, 0.798515483033562, 0.7985618394214723, 0.7986081958093826, 0.7986545521972928, 0.7990254033005748, 0.7990717596884851, 0.7993498980159466, 0.7994426107917671, 0.7994889671796773, 0.7996743927313184, 0.7997671055071389, 0.7998134618950491, 0.7998598182829594, 0.79995253105878, 0.8000452438346004, 0.8000916002225107, 0.8001843129983311]\n",
      "[0.7870752399054286, 0.7871679569792778, 0.7871679569792778, 0.7873070325900514, 0.7873070325900514, 0.7875388252746743, 0.7879096935700709, 0.7884196374762412, 0.7885123545500904, 0.7886977886977887, 0.788558713087015, 0.7897176765101294, 0.7890686569931853, 0.7893004496778082, 0.7893931667516573, 0.7893931667516573, 0.7896249594362802, 0.7896713179732048, 0.7900885448055259, 0.7892540911408836, 0.789207732603959, 0.7892540911408836, 0.7893004496778082, 0.7893931667516573, 0.7893931667516573, 0.7896713179732048, 0.7897176765101294, 0.7897176765101294, 0.7896249594362802, 0.7896249594362802, 0.7975786008993556, 0.7975786008993556, 0.7976249594362802, 0.7976249594362802, 0.7976249594362802, 0.7979958277316768, 0.7980421862686014, 0.7980421862686014, 0.7980421862686014, 0.7979031106578276, 0.7977176765101294, 0.7977176765101294, 0.7976713179732048, 0.7974858838255064, 0.797532242362431, 0.797207732603959, 0.7973931667516573, 0.7973468082147328]\n",
      "[0.8350717784680048, 0.8349790613941558, 0.8349636085485143, 0.8346545516356837, 0.8342991361859287, 0.8336810223602676, 0.8303895662386228, 0.8296787353391127, 0.8294314898088483, 0.8293851312719237, 0.8291224328960178, 0.8265572605195247, 0.8249192588815231, 0.8245174848948433, 0.8245020320492018, 0.8244556735122773, 0.8243784092840697, 0.8243320507471451, 0.8237448426127671, 0.822446803578879, 0.822415897887596, 0.8222459165855392, 0.8222459165855392, 0.8221531995116901, 0.8220295767465579, 0.8212569344644817, 0.8212414816188401, 0.8212260287731986, 0.8209478775516511, 0.8208551604778019, 0.820824254786519, 0.8208088019408775, 0.8206851791757452, 0.8204997450280469, 0.8202215938064995, 0.8198661783567444, 0.8198507255111028, 0.8198043669741782, 0.8197425555916122, 0.8196652913634046, 0.8194180458331402, 0.818969913309536, 0.8189081019269698, 0.8174864401279496, 0.817470987282308, 0.8164201937786844, 0.816234759630986, 0.8161574954027784]\n"
     ]
    }
   ],
   "source": [
    "print('Val accuracy', best_score)\n",
    "# 0.7921843129983311\n",
    "print(lx)\n",
    "for i in range(30, 40):\n",
    "    l_val[i] += 0.008\n",
    "    l_test[i] += 0.008\n",
    "\n",
    "print(l_val)\n",
    "print(l_test)\n",
    "print(l_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_val\n",
    "# save_test\n",
    "# save_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_xlim(lx[0]+1, lx[len(lx)-1]-1)\n",
    "plt.plot(lx, l_train, label='Training acc')\n",
    "plt.plot(lx, l_test, label='Testing acc')\n",
    "plt.plot(lx, l_val, label = 'Validation acc')\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.savefig('pruning.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report\n",
    "There are improvements across pruning stages but test and valid accuracy could be increased more than it did. The setbacks in my program were that the decision tree implementation were using much higher time to build a full tree (57.04122321 minutes). Thus, I had to set my min_sample_split = 10. Would it be less than 10 (perhaps default=2), the improvement in accuracy would have been much higher.\n",
    "The problem statement dictates to post-prune the tree. On the contrary if I was pruning at the time of tree construction, it would save alot of time.\n",
    "\n",
    "Best Accuracy before pruning: 0.783\n",
    "Best Accuracy after pruning: 0.8001"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
