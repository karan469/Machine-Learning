{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "csv_loaded = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likely(thetas_given_negative, thetas_given_positive, phis, string):\n",
    "    lst = string.split(' ')\n",
    "\n",
    "    log_y_0 = math.log(phis[4])\n",
    "    for i in range(len(lst)):\n",
    "        lst[i] = lst[i].lower()\n",
    "        if(lst[i] in thetas_given_positive):\n",
    "            log_y_0 += math.log(thetas_given_positive[lst[i]])\n",
    "\n",
    "\n",
    "    log_y_1 = math.log(phis[0])\n",
    "    for i in range(len(lst)):\n",
    "        lst[i] = lst[i].lower()\n",
    "        if(lst[i] in thetas_given_negative):\n",
    "            log_y_1 += math.log(thetas_given_negative[lst[i]])\n",
    "    \n",
    "    ss = log_y_0 + log_y_1\n",
    "    log_y_0 /= ss\n",
    "    log_y_1 /= ss\n",
    "    if(log_y_0>log_y_1):\n",
    "        return 0\n",
    "    return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_phi(df0):\n",
    "    phis = {}\n",
    "    df_positive = df0[df0['Y']==4]\n",
    "    df_negative = df0[df0['Y']==0]\n",
    "\n",
    "    phis[0] = df_negative.size/6\n",
    "    phis[4] = df_positive.size/6\n",
    "    \n",
    "    return phis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_theta_given_y(df1, df2, df3):\n",
    "    thetas_given_positive = {}\n",
    "    thetas_given_negative = {}\n",
    "\n",
    "    for i in range(1,df2['frequency'].size):\n",
    "        thetas_given_positive[df2['word'][i]] = (1+df2['frequency'][i])/(df1['frequency'].size + df2['frequency'][1:].sum())\n",
    "\n",
    "    for i in range(1,df3['frequency'].size):\n",
    "        thetas_given_negative[df3['word'][i]] = (1+df3['frequency'][i])/(df1['frequency'].size + df3['frequency'][1:].sum())\n",
    "    return thetas_given_positive, thetas_given_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df0, df1, df2, df3):\n",
    "    phis = calculate_phi(df0)\n",
    "    thetas_given_positive, thetas_given_negative = calculate_theta_given_y(df1, df2, df3)\n",
    "    return phis, thetas_given_positive, thetas_given_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(phis, thetas_given_positive, thetas_given_negative, test_file):\n",
    "    test_result = []\n",
    "    df_test = pd.read_csv(test_file)\n",
    "    for i in range(df_test['Y'].size):\n",
    "        result = log_likely(thetas_given_negative, thetas_given_positive, phis, df_test['text'][i])\n",
    "        test_result.append(result)\n",
    "    df_test['Y_test'] = test_result\n",
    "    \n",
    "    accuracy = 0\n",
    "    total = 0\n",
    "    confusion_martix = [[0,0],[0,0]]\n",
    "    for i in range(df_test['Y'].size):\n",
    "        if(df_test['Y'][i]!=2):\n",
    "            if(df_test['Y'][i]==df_test['Y_test'][i]):\n",
    "                accuracy += 1\n",
    "                if(df_test['Y'][i]==0):\n",
    "                    confusion_martix[0][0] += 1\n",
    "                else:\n",
    "                    confusion_martix[1][1] += 1\n",
    "            \n",
    "            if(df_test['Y'][i] == 0 and df_test['Y_test'][i] == 4):\n",
    "                confusion_martix[1][0] += 1\n",
    "            elif(df_test['Y'][i] == 4 and df_test['Y_test'][i] == 0):\n",
    "                confusion_martix[0][1] += 1\n",
    "            total += 1\n",
    "    return (accuracy/total), confusion_martix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "def main(train_file, test_file, wordbag_dest, positive_wordbag_dest, negative_wordbag_dest):\n",
    "    if(csv_loaded==False):\n",
    "        df0 = pd.read_csv(train_file)\n",
    "        df1 = pd.read_csv(wordbag_dest)\n",
    "        df2 = pd.read_csv(positive_wordbag_dest)\n",
    "        df3 = pd.read_csv(negative_wordbag_dest)\n",
    "        csv_loaded = True\n",
    "    phis, thetas_given_positive, thetas_given_negative = train(df0, df1, df2, df3)\n",
    "    train_accuracy, confusion_matrix_train = test(phis, thetas_given_positive, thetas_given_negative, train_file)\n",
    "    test_accuracy, confusion_matrix_test = test(phis, thetas_given_positive, thetas_given_negative, test_file)\n",
    "    print('Training Accuracy is ' + str(train_accuracy*100) + '%')\n",
    "    print('Testing Accuracy is ' + str(test_accuracy*100) + '%')\n",
    "    print('Confusion Matrix for Testing Data: \\n', confusion_matrix_test)\n",
    "    print('-ve tweets accuracy: %s' % str(confusion_matrix_test[0][0]/(confusion_matrix_test[0][0]+confusion_matrix_test[1][0])))\n",
    "    print('+ve tweets accuracy: %s' % str(confusion_matrix_test[1][1]/(confusion_matrix_test[1][1]+confusion_matrix_test[0][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy is 68.49875%\n",
      "Testing Accuracy is 69.91643454038997%\n",
      "Confusion Matrix for Testing Data: \n",
      " [[136, 67], [41, 115]]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    training_size = 1600000\n",
    "    data_folder = 'trainingandtestdata'\n",
    "    train_file = './'+data_folder+'/'+'training.csv'\n",
    "    test_file = './' + data_folder+'/'+'testing.csv'\n",
    "    wordbag_dest = './' + data_folder + '/wordbag.csv'\n",
    "    positive_wordbag_dest = './' + data_folder + '/positive_wordbag.csv'\n",
    "    negative_wordbag_dest = './' + data_folder + '/negative_wordbag.csv'\n",
    "    main(train_file, test_file, wordbag_dest, positive_wordbag_dest, negative_wordbag_dest)\n",
    "    \n",
    "# Training Accuracy is 64.6699375%\n",
    "# Testing Accuracy is 66.01671309192201%"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Training Accuracy is 68.49875%\n",
    "Testing Accuracy is 69.91643454038997%\n",
    "Confusion Matrix for Testing Data: \n",
    " [[136, 67], [41, 115]]\n",
    "\n",
    "This implies my model is predicting more negative (false) than positive (false).\n",
    "Model is predicting -ve tweets very well but not +ve tweets.\n",
    "\n",
    "-ve tweets accuracy: 0.768361581920904\n",
    "+ve tweets accuracy: 0.6318681318681318"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0b4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
