{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_data = np.array(df['text'])\n",
    "# labels = [1]*(training_size//2) + [0]*(training_size//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size = 1600000\n",
    "data_folder = 'trainingandtestdata'\n",
    "train_file = './'+data_folder+'/'+'training.csv'\n",
    "test_file = './' + data_folder+'/'+'testing.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# from nltk import sent_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import bigrams\n",
    "tk = RegexpTokenizer('^(@)', gaps = True)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "lancaster=LancasterStemmer()\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.add('be')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(train_file)\n",
    "del df['Id']\n",
    "del df['Query']\n",
    "del df['Username']\n",
    "del df['Date']\n",
    "\n",
    "def preprocess(df):\n",
    "    df['text'] = df['text'].apply(lambda x: x.lower())\n",
    "    df['text'] = df['text'].apply(lambda x: x.replace('.',' '))\n",
    "    df['text'] = df['text'].apply(lambda x: x.replace('\\n',' '))\n",
    "    df['text'] = df['text'].apply(lambda x: x.replace('?',' '))\n",
    "    df['text'] = df['text'].apply(lambda x: x.replace('!',' '))\n",
    "    df['text'] = df['text'].apply(lambda x: x.replace('\"',' '))\n",
    "    df['text'] = df['text'].apply(lambda x: x.replace(';',' '))\n",
    "    df['text'] = df['text'].apply(lambda x: x.replace('#',''))\n",
    "    df['text'] = df['text'].apply(lambda x: x.replace(',',' '))\n",
    "    df['text'] = df['text'].apply(lambda x: x.replace('\\'',' '))\n",
    "    \n",
    "preprocess(df)\n",
    "\n",
    "positive = df[df['Y']==4]\n",
    "negative = df[df['Y']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = positive['text'].str.split(' ', expand=True).stack().value_counts()\n",
    "d = {'word': array.index, 'frequency':array}\n",
    "# df2 = pd.DataFrame(data = d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_voc = pd.DataFrame(data = d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = negative['text'].str.split(' ', expand=True).stack().value_counts()\n",
    "d = {'word': array.index, 'frequency':array}\n",
    "neg_voc = pd.DataFrame(data = d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_voc_size = pos_voc['frequency'][0] + neg_voc['frequency'][0]\n",
    "pos_voc['word'] = pos_voc['word'][1:]\n",
    "pos_voc['frequency'] = pos_voc['frequency'][1:]\n",
    "\n",
    "neg_voc['word'] = neg_voc['word'][1:]\n",
    "neg_voc['frequency'] = neg_voc['frequency'][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_voc_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {'word': [], 'frequency': []}\n",
    "for i in range(1, pos_voc['word'].size):\n",
    "    if(pos_voc['word'][i] in vocab['word']):\n",
    "        index =  vocab['word'].index(pos_voc['word'][i])\n",
    "        vocab['frequency'][index] += pos_voc['frequency'][i]\n",
    "    else:\n",
    "        vocab['word'].append(pos_voc['word'][i])\n",
    "        vocab['frequency'].append(pos_voc['frequency'][i])\n",
    "    print(i)\n",
    "print('HALF DONE')\n",
    "\n",
    "for i in range(1, neg_voc['word'].size):\n",
    "    if(neg_voc['word'][i] in vocab['word']):\n",
    "        index =  vocab['word'].index(neg_voc['word'][i])\n",
    "        vocab['frequency'][index] += neg_voc['frequency'][i]\n",
    "    else:\n",
    "        vocab['word'].append(neg_voc['word'][i])\n",
    "        vocab['frequency'].append(neg_voc['frequency'][i])\n",
    "df1 = pd.DataFrame(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likely(thetas_given_negative, thetas_given_positive, phis, string):\n",
    "    lst = string.split(' ')\n",
    "\n",
    "    log_y_0 = math.log(phis[4])\n",
    "    for i in range(len(lst)):\n",
    "        lst[i] = lst[i].lower()\n",
    "        if(lst[i] in thetas_given_positive):\n",
    "            log_y_0 += math.log(thetas_given_positive[lst[i]])\n",
    "\n",
    "\n",
    "    log_y_1 = math.log(phis[0])\n",
    "    for i in range(len(lst)):\n",
    "        lst[i] = lst[i].lower()\n",
    "        if(lst[i] in thetas_given_negative):\n",
    "            log_y_1 += math.log(thetas_given_negative[lst[i]])\n",
    "    \n",
    "    ss = log_y_0 + log_y_1\n",
    "    log_y_0 /= ss\n",
    "    log_y_1 /= ss\n",
    "    if(log_y_0>log_y_1):\n",
    "        return 0\n",
    "    return 4\n",
    "def calculate_phi(df0):\n",
    "    phis = {}\n",
    "    df_positive = df0[df0['Y']==4]\n",
    "    df_negative = df0[df0['Y']==0]\n",
    "\n",
    "    phis[0] = df_negative.size/6\n",
    "    phis[4] = df_positive.size/6\n",
    "    \n",
    "    return phis\n",
    "def calculate_theta_given_y(df1, df2, df3):\n",
    "    thetas_given_positive = {}\n",
    "    thetas_given_negative = {}\n",
    "\n",
    "    for i in range(1,df2['frequency'].size):\n",
    "        thetas_given_positive[df2['word'][i]] = (1+df2['frequency'][i])/(df1['frequency'].size + df2['frequency'][1:].sum())\n",
    "\n",
    "    for i in range(1,df3['frequency'].size):\n",
    "        thetas_given_negative[df3['word'][i]] = (1+df3['frequency'][i])/(df1['frequency'].size + df3['frequency'][1:].sum())\n",
    "    return thetas_given_positive, thetas_given_negative\n",
    "def train(df0, df1, df2, df3):\n",
    "    phis = calculate_phi(df0)\n",
    "    thetas_given_positive, thetas_given_negative = calculate_theta_given_y(df1, df2, df3)\n",
    "    return phis, thetas_given_positive, thetas_given_negative\n",
    "def test(phis, thetas_given_positive, thetas_given_negative, test_file):\n",
    "    test_result = []\n",
    "    df_test = pd.read_csv(test_file)\n",
    "    for i in range(df_test['Y'].size):\n",
    "        result = log_likely(thetas_given_negative, thetas_given_positive, phis, df_test['text'][i])\n",
    "        test_result.append(result)\n",
    "    df_test['Y_test'] = test_result\n",
    "    \n",
    "    accuracy = 0\n",
    "    total = 0\n",
    "    confusion_martix = [[0,0],[0,0]]\n",
    "    for i in range(df_test['Y'].size):\n",
    "        if(df_test['Y'][i]!=2):\n",
    "            if(df_test['Y'][i]==df_test['Y_test'][i]):\n",
    "                accuracy += 1\n",
    "                if(df_test['Y'][i]==0):\n",
    "                    confusion_martix[0][0] += 1\n",
    "                else:\n",
    "                    confusion_martix[1][1] += 1\n",
    "            \n",
    "            if(df_test['Y'][i] == 0 and df_test['Y_test'][i] == 4):\n",
    "                confusion_martix[1][0] += 1\n",
    "            elif(df_test['Y'][i] == 4 and df_test['Y_test'][i] == 0):\n",
    "                confusion_martix[0][1] += 1\n",
    "            total += 1\n",
    "    return (accuracy/total), confusion_martix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phis, thetas_given_positive, thetas_given_negative = train(df, df1, pos_voc, neg_voc)\n",
    "# train_accuracy, confusion_matrix_train = test(phis, thetas_given_positive, thetas_given_negative, train_file)\n",
    "test_accuracy, confusion_matrix_test = test(phis, thetas_given_positive, thetas_given_negative, test_file)\n",
    "# print('Training Accuracy is ' + str(train_accuracy*100) + '%')\n",
    "print('Testing Accuracy is ' + str(test_accuracy*100) + '%')\n",
    "print('Confusion Matrix for Testing Data: \\n', confusion_matrix_test)\n",
    "print('-ve tweets accuracy: %s' % str(confusion_matrix_test[0][0]/(confusion_matrix_test[0][0]+confusion_matrix_test[1][0])))\n",
    "print('+ve tweets accuracy: %s' % str(confusion_matrix_test[1][1]/(confusion_matrix_test[1][1]+confusion_matrix_test[0][1])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0b4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
